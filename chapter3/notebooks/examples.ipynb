{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要に応じてインストール\n",
    "# !pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 OpenAI  APIの基本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.2 OpenAI APIの使い方"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基本的なコード例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# クライアントを定義\n",
    "client = OpenAI(api_key=\"ここにAPIキーを入れます\")\n",
    "\n",
    "# Chat Completion APIの呼び出し例\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"こんにちは、今日はどんな天気ですか？\"}],\n",
    ")\n",
    "\n",
    "# 応答内容を出力\n",
    "print(\"Response:\", response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "消費されたトークン数の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 消費されたトークン数の表示\n",
    "tokens_used = text_response.usage\n",
    "print(\"Prompt Tokens:\", tokens_used.prompt_tokens)\n",
    "print(\"Completion Tokens:\", tokens_used.completion_tokens)\n",
    "print(\"Total Tokens:\", tokens_used.total_tokens)\n",
    "print(\"Completion_tokens_details:\", tokens_used.completion_tokens_details)\n",
    "print(\"Prompt_tokens_details:\", tokens_used.prompt_tokens_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.5 構造化出力（Structured Outputs）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "jsonモードの設定例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    response_format={\"type\": \"json_object\"},\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"あなたは JSON を出力するように設計された便利なアシスタントです。\",\n",
    "        },\n",
    "        {\"role\": \"assistant\", \"content\": '{\"output\": String}'},\n",
    "        {\"role\": \"user\", \"content\": \"2020 年のワールド シリーズの優勝者は誰ですか?\"},\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structured Outputsの実行例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "# Pydanticモデルを定義\n",
    "class NewsArticle(BaseModel):\n",
    "    title: str\n",
    "    author: str\n",
    "    date: str\n",
    "    content: str\n",
    "\n",
    "\n",
    "response = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"今日の天気に関するニュース記事を書いてください\"}\n",
    "    ],\n",
    "    temperature=0,\n",
    "    response_format=NewsArticle,  # Structured Outputsに対応するPydanticモデルを指定\n",
    ")\n",
    "\n",
    "# 生成された記事情報の表示\n",
    "article = completion.choices[0].message.parsed\n",
    "print(\"Title:\", article.title)\n",
    "print(\"Author:\", article.author)\n",
    "print(\"Date:\", article.date)\n",
    "print(\"Content:\", article.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Function callingの活用方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3.1 Function callingの使い方"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "# 天気情報を取得するダミー関数\n",
    "def get_weather(location):\n",
    "    # 実際のAPI呼び出し部分を簡略化\n",
    "    weather_info = {\n",
    "        \"Tokyo\": \"晴れ、気温25度\",\n",
    "        \"Osaka\": \"曇り、気温22度\",\n",
    "        \"Kyoto\": \"雨、気温18度\",\n",
    "    }\n",
    "    return weather_info.get(location, \"天気情報が見つかりません\")\n",
    "\n",
    "\n",
    "# 初回のユーザーメッセージ\n",
    "messages = [{\"role\": \"user\", \"content\": \"東京の天気を教えてください\"}]\n",
    "\n",
    "# モデルに提供するToolの定義\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"指定された場所の天気情報を取得します\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"都市名（例: Tokyo）\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "# モデルへの最初のAPIリクエスト\n",
    "response = client.chat.completions.create(\n",
    "    model=deployment_name,\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    ")\n",
    "\n",
    "# モデルの応答を処理\n",
    "response_message = response.choices[0].message\n",
    "messages.append(response_message)\n",
    "\n",
    "print(\"モデルからの応答:\")\n",
    "print(response_message)\n",
    "\n",
    "# 関数呼び出しを処理\n",
    "if response_message.tool_calls:\n",
    "    for tool_call in response_message.tool_calls:\n",
    "        if tool_call.function.name == \"get_weather\":\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            print(f\"関数の引数: {function_args}\")\n",
    "            weather_response = get_weather(location=function_args.get(\"location\"))\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": \"get_weather\",\n",
    "                    \"content\": weather_response,\n",
    "                }\n",
    "            )\n",
    "else:\n",
    "    print(\"モデルによるツール呼び出しはありませんでした。\")\n",
    "\n",
    "# モデルへの最終的なAPIリクエスト\n",
    "final_response = client.chat.completions.create(\n",
    "    model=deployment_name,\n",
    "    messages=messages,\n",
    ")\n",
    "\n",
    "print(\"Final Response:\", response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4 生成AIエージェントで利用されるTool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4.1 WEB検索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tools = [TavilySearchResults(max_results=3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "# 引数スキーマを定義\n",
    "class AddArgs(BaseModel):\n",
    "    a: int\n",
    "    b: int\n",
    "\n",
    "\n",
    "@tool(args_schema=AddArgs)\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"\n",
    "    このToolは2つの整数を引数として受け取り、それらの合計を返します。\n",
    "\n",
    "    Args:\n",
    "        a (int): 加算する最初の整数。\n",
    "        b (int): 加算する2つ目の整数。\n",
    "\n",
    "    Returns:\n",
    "        int: 2つの整数の合計値。\n",
    "\n",
    "    使用例:\n",
    "        例:\n",
    "            入力: {\"a\": 3, \"b\": 5}\n",
    "            出力: 8\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "# 実行例\n",
    "args = {\"a\": 5, \"b\": 10}\n",
    "result = add(**args)\n",
    "print(f\"Result: {result}\")  # Result: 15\n",
    "\n",
    "# Toolに関連付けられている属性の確認\n",
    "print(add.name)\n",
    "print(add.description)\n",
    "print(add.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChainを使ったDuckduckgoのカスタムツールの例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from duckduckgo_search import DDGS\n",
    "\n",
    "\n",
    "class DDGSearchInput(BaseModel):\n",
    "    \"\"\"検索クエリが文字列であることをバリデーションします。\n",
    "    文字列以外のデータ型の検索入力を受け付けません。\n",
    "    \"\"\"\n",
    "\n",
    "    query: str = Field(description=\"検索キーワードを入力してください\")\n",
    "\n",
    "\n",
    "@tool(args_schema=DDGSearchInput)\n",
    "def duckduckgo_search(query: str, max_result_num: int = 5) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    このToolはDuckDuckGoを使用してWeb検索を実行します。\n",
    "\n",
    "    機能:\n",
    "        このToolは指定されたキーワード（query）でDuckDuckGo検索を行い、\n",
    "        検索結果から指定した数（max_result_num）までの結果を取得します。\n",
    "        各検索結果にはタイトル、スニペット、およびURLが含まれます。\n",
    "\n",
    "    Args:\n",
    "        query (str): 検索キーワード。\n",
    "        max_result_num (int): 取得する検索結果の最大数。デフォルトは5。\n",
    "\n",
    "    Returns:\n",
    "        List[Dict[str, str]]: 検索結果のリスト。各要素は以下の形式の辞書です:\n",
    "            - \"title\" (str): 検索結果のタイトル。\n",
    "            - \"snippet\" (str): 検索結果のスニペット（概要）。\n",
    "            - \"url\" (str): 検索結果のURL。\n",
    "    \"\"\"\n",
    "    with DDGS() as ddgs:\n",
    "        responce = ddgs.text(query, region=\"jp-jp\", safesearch=\"off\", backend=\"lite\")\n",
    "        return [\n",
    "            {\n",
    "                \"title\": r.get(\"title\", \"\"),\n",
    "                \"snippet\": r.get(\"body\", \"\"),\n",
    "                \"url\": r.get(\"href\", \"\"),\n",
    "            }\n",
    "            for r in islice(responce, max_result_num)\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML取得\n",
    "import requests\n",
    "\n",
    "response = requests.get(url)\n",
    "html_content = response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQLDatabaseChainの使用例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_core.tools import tool\n",
    "from pydantic import BaseModel\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "\n",
    "# 引数スキーマを定義\n",
    "class SQLQueryArgs(BaseModel):\n",
    "    keywords: str\n",
    "    \n",
    "@tool(args_schema=SQLQueryArgs)\n",
    "def text_to_sql_search(keywords: str):\n",
    "\t\t\"\"\"\n",
    "\t\t自然言語でのクエリをSQLクエリに変換し、SQLデータベースで検索を実行します。\n",
    "\n",
    "    機能:\n",
    "        - このToolは、与えられた自然言語形式のキーワードをもとに、SQLクエリを生成します。\n",
    "        - LLMを使用してSQL文を生成し、PostgreSQLデータベースで検索を実行します。\n",
    "        - 取得した検索結果を返します。\n",
    "\n",
    "    Args:\n",
    "        keywords (str): 実行したいクエリの自然言語キーワード。\n",
    "            例: \"2023年の売上が最大の月を教えてください\"\n",
    "\n",
    "    Returns:\n",
    "        Any: データベース検索結果を返します。\n",
    "\t\t\"\"\"\n",
    "    \n",
    "    # PostgreSQLデータベース接続パラメータを設定する\n",
    "    db_url = f\"postgresql+psycopg2://{os.getenv('PGUSER')}:{os.getenv('PGPASSWORD')}@{os.getenv('PGHOST')}:5432/{os.getenv('PGDATABASE')}\"\n",
    "    db = SQLDatabase.from_uri(db_url)\n",
    "\n",
    "    llm = AzureChatOpenAI(\n",
    "        deployment_name=model_name, \n",
    "        api_key= os.getenv(\"OPENAI_API_KEY\"),  \n",
    "        api_version=os.getenv(\"OPENAI_API_VERSION\"),\n",
    "        azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    )\n",
    "    \n",
    "    # SQLチェーンの設定\n",
    "    db_chain = SQLDatabaseChain(llm=llm, database=db, verbose=True)\n",
    "    \n",
    "    # 実行\n",
    "    response = db_chain.run(keywords)\n",
    "    \n",
    "    return response\n",
    "\n",
    "# 実行例\n",
    "args = {\"keywords\": \"employeeテーブルの情報は何件ありますか？\"}\n",
    "response = text_to_sql_search(**args)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Assistants APIを用いたCode Interepreterの使用例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# クライアントを定義\n",
    "client = OpenAI(api_key=\"ここにAPIキーを入れます\")\n",
    "\n",
    "# クライアントを定義（Azureの場合）\n",
    "# client = AzureOpenAI(\n",
    "#    api_key= os.getenv(\"OPENAI_API_KEY\"),\n",
    "#    api_version=\"2024-02-15-preview\", #2024-02-15-preview以降のapi_version\n",
    "#    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "#    )\n",
    "\n",
    "# 処理させたいファイルを指定\n",
    "file = client.files.create(\n",
    "    file=open(\"処理させたいファイルのPATH\", \"rb\"), purpose=\"assistants\"\n",
    ")\n",
    "\n",
    "# assistantを定義\n",
    "assistant = client.beta.assistants.create(\n",
    "    instructions=\"あなたは、数学の問題に答えるためのコードを書くことができる AI アシスタントです。\",\n",
    "    model=f\"{model_name}\",\n",
    "    tools=[{\"type\": \"code_interpreter\"}],\n",
    "    file_ids=[file.id],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print.pyの中身\n",
    "str = \"!!!\"\n",
    "print(f\"hello world{str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.7 LangGraphによるエージェントワークフロー構築"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.7.2 エージェントワークフローの構築方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要に応じてインストール\n",
    "# pip install langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 状態（State）とワークフローの初期化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangGraphでエージェントのワークフローの初期化\n",
    "import operator\n",
    "from typing import TypedDict, List, Tuple, Annotated\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "\n",
    "# ワークフロー前端の状態を記録するためのクラス\n",
    "# 基本的に各ノードにこのクラスが引数に渡される\n",
    "class AgentState(TypedDict):\n",
    "    input: str  # ユーザの入力\n",
    "    plans: List[str]  # 計画ノードの結果\n",
    "    feedbacks: List[str]  # 振り返りノードの結果\n",
    "    output: str  # 生成ノードの結果\n",
    "    iteration: int\n",
    "\n",
    "\n",
    "# Graph全体を定義\n",
    "workflow = StateGraph(AgentState)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. ノードとエッジの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangGraphでエージェントワークフローの構築\n",
    "\n",
    "\n",
    "# 各ノードの処理、エッジでの条件判定関数を定義（ここでは省略）\n",
    "def plan_node(state: State):\n",
    "    pass\n",
    "\n",
    "\n",
    "def generation_node(state: State):\n",
    "    pass\n",
    "\n",
    "\n",
    "def reflection_node(state: State):\n",
    "    pass\n",
    "\n",
    "\n",
    "# 使用するノードを追加。ノード名と対応する関数を書く。名前はこの後も使うので一意である必要がある\n",
    "workflow.add_node(\"planner\", plan_node)\n",
    "workflow.add_node(\"generator\", generation_node)\n",
    "workflow.add_node(\"reflector\", reflection_node)\n",
    "\n",
    "# エントリーポイントを定義。これが最初に呼ばれるノード\n",
    "workflow.add_edge(START, \"planner\")\n",
    "\n",
    "\n",
    "# 条件付きエッジ用の条件。3回イテレーションする\n",
    "def should_continue(state: AgentState):\n",
    "    if len(state[\"iteration\"]) > 3:\n",
    "        # End after 3 iterations\n",
    "        return END\n",
    "    return \"reflector\"\n",
    "\n",
    "\n",
    "# ノードをつなぐエッジを追加\n",
    "workflow.add_edge(\"planner\", \"generator\")\n",
    "workflow.add_conditional_edges(\"generator\", should_continue, [\"reflector\", END])\n",
    "workflow.add_edge(\"reflector\", \"generator\")\n",
    "\n",
    "\n",
    "# 最後にworkflowをコンパイルする。これでLangChainのrunnnableな形式になる\n",
    "# runnnableになることでinvokeやstreamが使用できるようになる\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# エージェントのワークフローの実行\n",
    "inputs = {\n",
    "    \"input\": \"LangGraphを用いたエージェントワークフロー構築方法のブログ記事を作成して\",\n",
    "}\n",
    "\n",
    "for s in app.stream(inputs):\n",
    "    print(list(s.values())[0])\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# mermaidで描画\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
